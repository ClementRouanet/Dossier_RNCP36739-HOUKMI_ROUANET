{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "import pyspark.sql.functions as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "outputs": [],
      "metadata": {
        "microsoft": {}
      },
      "source": [
        "# Liste des fichiers CSV\r\n",
        "csv_files = {\r\n",
        "    \"customers\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/raw_data/customers.csv\",\r\n",
        "    \"sellers\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/raw_data/sellers.csv\",\r\n",
        "    \"orders\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/raw_data/orders.csv\",\r\n",
        "    \"order_items\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/raw_data/order_items.csv\",\r\n",
        "    \"order_payments\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/raw_data/order_payments.csv\",\r\n",
        "    \"order_reviews\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/raw_data/order_reviews.csv\",\r\n",
        "    \"products\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/raw_data/products.csv\",\r\n",
        "    \"products_translated\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/raw_data/product_category_name_translation.csv\",\r\n",
        "    \"geolocation\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/raw_data/geolocation.csv\",\r\n",
        "    \"states_name\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/raw_data/states_name.csv\"\r\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Créer un dictionnaire de DataFrames\r\n",
        "dataframes = {name: spark.read.csv(path, header=True, inferSchema=True) for name, path in csv_files.items()}\r\n",
        "dataframes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Changement type variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dataframes[\"order_reviews\"] = dataframes[\"order_reviews\"] \\\r\n",
        "    .withColumn(\"review_creation_date_good\", F.to_timestamp(\"review_creation_date\", \"yyyy-MM-dd HH:mm:ss\")) \\\r\n",
        "    .withColumn(\"review_answer_timestamp_good\", F.to_timestamp(\"review_answer_timestamp\", \"yyyy-MM-dd HH:mm:ss\")) \\\r\n",
        "    .drop(\"review_creation_date\", \"review_answer_timestamp\") \\\r\n",
        "    .withColumnRenamed(\"review_creation_date_good\", \"review_creation_date\") \\\r\n",
        "    .withColumnRenamed(\"review_answer_timestamp_good\", \"review_answer_timestamp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dataframes[\"order_reviews\"].printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Nettoyage des données dupliquées"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Parcourir chaque DataFrame et compter les lignes dupliquées\r\n",
        "for key, df in dataframes.items():\r\n",
        "    duplicate_rows = df.groupBy(df.columns).count().where(F.col(\"count\") > 1)\r\n",
        "    print(f\"Duplicates lines in {key} DataFrame : {duplicate_rows.count()}\")\r\n",
        "    if duplicate_rows.count() > 0 :\r\n",
        "        duplicate_rows.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Suppression des lignes dupliquées dans le Dataframe geolocation\r\n",
        "dataframes[\"geolocation\"] = dataframes[\"geolocation\"].dropDuplicates()\r\n",
        "\r\n",
        "# Vérification que les lignes dupliquées ont bien été supprimées\r\n",
        "print(f\"Duplicates lines in geolocation DataFrame : {duplicate_rows.count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Remplacement noms catégories de portugais à anglais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Vérification que toutes les catégories en portugais ont une traduction en anglais\r\n",
        "p = dataframes[\"products\"].select(\"product_category_name\").distinct()\r\n",
        "t = dataframes[\"products_translated\"].select(\"product_category_name\").distinct()\r\n",
        "\r\n",
        "p.subtract(t).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Jointure entre products et products_translated sur la colonne product_category_name\r\n",
        "joined_df = dataframes[\"products\"].alias(\"p\") \\\r\n",
        "    .join(\r\n",
        "        dataframes[\"products_translated\"].alias(\"pt\"),\r\n",
        "        F.col(\"p.product_category_name\") == F.col(\"pt.product_category_name\"),\r\n",
        "        \"left\"\r\n",
        "    )\r\n",
        "\r\n",
        "# Suppression du champs avec le om du produit en portugais\r\n",
        "joined_df = joined_df.drop(\"product_category_name\")\r\n",
        "\r\n",
        "# Renommage de la colonne product_category_name_english\r\n",
        "joined_df = joined_df.withColumnRenamed(\"product_category_name_english\", \"product_category_name\")\r\n",
        "\r\n",
        "# Réagencement des colonnes du DataFrame\r\n",
        "new_columns = [joined_df.columns[0]] + [\"product_category_name\"] + [col for col in joined_df.columns[1:-1]]\r\n",
        "dataframes[\"products\"] = joined_df.select(new_columns)\r\n",
        "\r\n",
        "# Mettre à jour le DataFrame dans le dictionnaire\r\n",
        "dataframes[\"products\"].show(5)\r\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Nettoyage des valeurs nulles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Fonction pour compter les valeurs nulles par colonne\r\n",
        "def count_nulls(df):\r\n",
        "    return df.select([F.sum(F.col(c).isNull().cast(\"int\")).alias(c) for c in df.columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Parcourir chaque DataFrame et compter les valeurs nulles\r\n",
        "for key, df in dataframes.items():\r\n",
        "    null_counts = count_nulls(df)\r\n",
        "    print(f\"Null values in {key} DataFrame :\")\r\n",
        "    null_counts.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Suppression des valuers nulles de \"order_reviews\"\r\n",
        "dataframes[\"order_reviews\"] = dataframes[\"order_reviews\"] \\\r\n",
        "    .filter(F.col(\"review_creation_date\").isNotNull() & F.col(\"review_answer_timestamp\").isNotNull())\r\n",
        "\r\n",
        "# Vérification que toutes les valeurs nulles de order_reviews ont été supprimées\r\n",
        "null_counts = count_nulls(dataframes[\"order_reviews\"])\r\n",
        "print(f\"Null values in order_reviews DataFrame :\")\r\n",
        "null_counts.show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Remplacement des valeurs nulles de \"products\" : String -> \"Other\"  &  Int -> -1\r\n",
        "dataframes[\"products\"] = dataframes[\"products\"] \\\r\n",
        "    .withColumn(\"product_category_name\", F.when(F.col(\"product_category_name\").isNull(), \"unknown\").otherwise(F.col(\"product_category_name\"))) \\\r\n",
        "    .withColumn(\"product_name_length\", F.when(F.col(\"product_name_length\").isNull(), -1).otherwise(F.col(\"product_name_length\"))) \\\r\n",
        "    .withColumn(\"product_description_length\", F.when(F.col(\"product_description_length\").isNull(), -1).otherwise(F.col(\"product_description_length\"))) \\\r\n",
        "    .withColumn(\"product_photos_qty\", F.when(F.col(\"product_photos_qty\").isNull(), -1).otherwise(F.col(\"product_photos_qty\"))) \\\r\n",
        "    .withColumn(\"product_weight_g\", F.when(F.col(\"product_weight_g\").isNull(), -1).otherwise(F.col(\"product_weight_g\"))) \\\r\n",
        "    .withColumn(\"product_length_cm\", F.when(F.col(\"product_length_cm\").isNull(), -1).otherwise(F.col(\"product_length_cm\"))) \\\r\n",
        "    .withColumn(\"product_height_cm\", F.when(F.col(\"product_height_cm\").isNull(), -1).otherwise(F.col(\"product_height_cm\"))) \\\r\n",
        "    .withColumn(\"product_width_cm\", F.when(F.col(\"product_width_cm\").isNull(), -1).otherwise(F.col(\"product_width_cm\")))\r\n",
        "\r\n",
        "# Vérification que toutes les valeurs nulles de products ont été remplacée\r\n",
        "null_counts = count_nulls(dataframes[\"products\"])\r\n",
        "print(f\"Null values in products DataFrame :\")\r\n",
        "null_counts.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Ajout  champs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dataframes[\"order_items\"] = dataframes[\"order_items\"] \\\r\n",
        "    .withColumn(\"total_items_value\", F.col(\"price\") * F.col(\"order_item_id\")) \\\r\n",
        "    .withColumn(\"total_freight_value\", F.col(\"freight_value\") * F.col(\"order_item_id\")) \\\r\n",
        "    .withColumn(\"total_order_value\", F.col(\"total_items_value\") + F.col(\"total_freight_value\"))\r\n",
        "\r\n",
        "dataframes[\"order_items\"].show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Chargement des Dataframes nettoyés en Parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Chemin de destination dans ADLS Gen2\r\n",
        "output_path = {\r\n",
        "    \"customers\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/cleaned_data/customers\",\r\n",
        "    \"sellers\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/cleaned_data/sellers\",\r\n",
        "    \"orders\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/cleaned_data/orders\",\r\n",
        "    \"order_items\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/cleaned_data/order_items\",\r\n",
        "    \"order_payments\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/cleaned_data/order_payments\",\r\n",
        "    \"order_reviews\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/cleaned_data/order_reviews\",\r\n",
        "    \"products\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/cleaned_data/products\",\r\n",
        "    \"products_translated\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/cleaned_data/products_translated\",\r\n",
        "    \"geolocation\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/cleaned_data/geolocation\",\r\n",
        "    \"states_name\": \"abfss://projetcloud@datalakecloud.dfs.core.windows.net/cleaned_data/states_name\"\r\n",
        "}\r\n",
        "\r\n",
        "# Écrire les DataFrame au format Parquet\r\n",
        "for key, df in dataframes.items() :\r\n",
        "    df.write.mode(\"overwrite\").parquet(output_path[key])"
      ]
    }
  ],
  "metadata": {
    "description": null,
    "save_output": true,
    "language_info": {
      "name": "python"
    }
  }
}